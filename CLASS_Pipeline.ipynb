{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff7f11d-043f-4aa4-9c29-686c7731f50a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1c04d12-080a-4448-b227-b7d08814e63d",
   "metadata": {},
   "source": [
    "### Pipeline to download CH2 CLASS data and plot its graph(count vs time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76c4f6a-ad02-4c8a-8886-69baf8f59879",
   "metadata": {},
   "source": [
    "In this pipeline, we will first download the data, then we will make a text file with all the zipfile names so that we can extract csv files from each,then we generate lightcurve csv files from each zip files, then we combine the csv files and then sort them and then plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b405ad46-d43a-4621-be7c-5b0089d5958e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f138968c-bf09-4e22-953b-c7015a10d687",
   "metadata": {},
   "source": [
    "update your pradhan username and password below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea2e2c80-32ff-4e5b-bec3-2adca48dca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "USER = \"username\"\n",
    "PASS = \"password\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d243be-9a8e-4235-9d35-8b1fadb07c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, edit the below section based on your requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d20754e0-495a-4230-b17d-3faf47e0fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = \"2023-10-01 00:00:00\"  # start datetime to be searched\n",
    "end = \"2023-10-31 23:59:59\"  # end datetime to be searched\n",
    "no_files = 51732  # Total number of files\n",
    "count = 0  # Starting index for download, change this from what is shown in website in case of break in download, add 500 to what value was shown in \"downloaded files from index no\"\n",
    "DOWNLOAD_DIR = '/path/to/downloaded/files'  # Directory for downloaded files, you have to create them initially\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5bfd75d-71e1-48cc-85c0-d0874c4244d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary libraries and modules:\n",
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "import shutil\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DayLocator, DateFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc79905e-bc20-4cf4-8a0c-82ebe4db16e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download geckodriver and update the below path\n",
    "service = Service(r'/path/to/geckodriver') #Directory where the geckodriver is kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3166b461-5b75-4f56-ad06-1525f65b84fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Firefox browser preferences\n",
    "profile = Options()\n",
    "profile.set_preference('browser.download.folderList', 2)  # custom location\n",
    "profile.set_preference('browser.download.dir', DOWNLOAD_DIR)\n",
    "profile.set_preference('browser.download.manager.showWhenStarting', False)\n",
    "profile.set_preference(\"browser.download.manager.showAlertOnComplete\", False)\n",
    "profile.set_preference(\"browser.helperApps.neverAsk.saveToDisk\", \"application/zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca4c248-4dc7-4f07-8d6b-f7af4f720837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to automatically download files from pradhan and log out from the website upon completion\n",
    "# Function to check status of download\n",
    "def did_you_download():\n",
    "    dpath = DOWNLOAD_DIR\n",
    "    os.chdir(dpath)\n",
    "    string = \".zip.part\"\n",
    "\n",
    "    while string == \".zip.part\":\n",
    "        files = sorted(os.listdir(dpath), key=os.path.getmtime)\n",
    "\n",
    "        if not files:\n",
    "            time.sleep(2)  # Wait and try again\n",
    "            continue  # Skip this iteration if no files are found\n",
    "\n",
    "        newfile = files[-1]\n",
    "        string = newfile[-9:]  # Check for the \".zip.part\" suffix\n",
    "        time.sleep(2)\n",
    "\n",
    "    status = \"Downloaded: \" + newfile\n",
    "    return status\n",
    "\n",
    "# Initialize the WebDriver\n",
    "options = Options()\n",
    "driver = webdriver.Firefox(service=service, options=options)\n",
    "driver.get(\"https://pradan.issdc.gov.in/ch2/\")\n",
    "\n",
    "# Find and click on \"Browse and Download\"\n",
    "BandD = driver.find_element(By.PARTIAL_LINK_TEXT, \"Browse and Download\")\n",
    "BandD.click()\n",
    "\n",
    "# Initialize a set to keep track of downloaded indexes\n",
    "downloaded_indexes = set()\n",
    "\n",
    "try:\n",
    "    # Logging into Pradan\n",
    "    username = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, \"username\"))\n",
    "    )\n",
    "    username.clear()\n",
    "    username.send_keys(USER)\n",
    "    time.sleep(2)\n",
    "\n",
    "    passwd = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, \"password\"))\n",
    "    )\n",
    "    passwd.clear()\n",
    "    passwd.send_keys(PASS)\n",
    "\n",
    "    time.sleep(2)\n",
    "    passwd.submit()\n",
    "    print(\"\\nLogged in.\")\n",
    "\n",
    "    # Selecting the section for CLASS on the website\n",
    "    print(\"Selecting CLASS.\")\n",
    "    time.sleep(10)\n",
    "    CLASS_data = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.ID, \"tableForm:payloads:0:j_idt42\"))\n",
    "    )\n",
    "    CLASS_data.click()\n",
    "\n",
    "    # Filtering the data according to START and END time of observation\n",
    "    print(\"Filtering data according to START and END time of observation.\")\n",
    "    From = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, \"filterForm:filterTable:0:datetime1_input\"))\n",
    "    )\n",
    "    From.clear()\n",
    "    From.send_keys(start)\n",
    "\n",
    "    To = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, \"filterForm:filterTable:0:datetime2_input\"))\n",
    "    )\n",
    "    To.clear()\n",
    "    To.send_keys(end)\n",
    "\n",
    "    time.sleep(2)\n",
    "    Filter = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, \"filterForm:filterButton\"))\n",
    "    )\n",
    "    Filter.click()\n",
    "    print(\"Ready to download.\")\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "    # Locate the dropdown menu and select \"DOWNLOAD\"\n",
    "    dropdown = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, \"filterForm:j_idt53\"))\n",
    "    )\n",
    "    select = Select(dropdown)\n",
    "    select.select_by_visible_text(\"DOWNLOAD\")  # Select the DOWNLOAD option\n",
    "\n",
    "    # Choosing the FITS files and downloading them as batches of 500 files\n",
    "    while count < no_files:\n",
    "        # Wait for any modal overlay to disappear before proceeding\n",
    "        print(\"Waiting for overlays to disappear...\")\n",
    "        WebDriverWait(driver, 60).until(\n",
    "            EC.invisibility_of_element_located((By.CSS_SELECTOR, \".ui-widget-overlay, .ui-dialog-mask\"))\n",
    "        )\n",
    "        print(\"Overlays have disappeared, continuing...\")\n",
    "\n",
    "        # Entering the starting index of the batch\n",
    "        print(\"waiting for selecting index\")\n",
    "        Start_index = WebDriverWait(driver, 60).until(\n",
    "            EC.presence_of_element_located((By.ID, \"tableForm:startIndex\"))\n",
    "        )\n",
    "        Start_index.clear()\n",
    "        Start_index.send_keys(count + 1)\n",
    "\n",
    "        # Wait until the \"Select\" button is clickable before interacting\n",
    "        print(\"waiting for select button\")\n",
    "        Select_button = WebDriverWait(driver, 15).until(\n",
    "            EC.element_to_be_clickable((By.ID, \"tableForm:selectButton\"))\n",
    "        )\n",
    "\n",
    "        # Retry mechanism in case click fails due to intercepted element\n",
    "        try:\n",
    "            Select_button.click()\n",
    "        except ElementClickInterceptedException:\n",
    "            print(\"Select button click intercepted. Retrying after waiting for overlay.\")\n",
    "            WebDriverWait(driver, 20).until(\n",
    "                EC.invisibility_of_element_located((By.CSS_SELECTOR, \".ui-widget-overlay, .ui-dialog-mask\"))\n",
    "            )\n",
    "            Select_button.click()\n",
    "\n",
    "        # Downloading the batch\n",
    "        time.sleep(30)\n",
    "        Download = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.ID, \"tableForm:download\"))\n",
    "        )\n",
    "        Download.click()\n",
    "\n",
    "        # Checking the status of download\n",
    "        time.sleep(1)\n",
    "        print(did_you_download())\n",
    "\n",
    "        # Marking the current batch as downloaded\n",
    "        for i in range(count, min(count + 500, no_files)):\n",
    "            downloaded_indexes.add(i)\n",
    "\n",
    "        print(\"downloaded files from index no: \", count)\n",
    "        count += 500\n",
    "        time.sleep(8)\n",
    "\n",
    "    # Final log of downloaded indexes\n",
    "    print(f\"Downloaded indexes: {downloaded_indexes}\")\n",
    "\n",
    "finally:\n",
    "    try:\n",
    "        # Locate the user menu dropdown using the div ID\n",
    "        user_menu = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"j_idt30\"))\n",
    "        )\n",
    "        user_menu.click()  # Click to open the user menu\n",
    "\n",
    "        # Wait for the dropdown items to become visible\n",
    "        logout_menu = WebDriverWait(driver, 10).until(\n",
    "            EC.visibility_of_element_located((By.CSS_SELECTOR, \".ui-menu-list.ui-helper-reset\"))\n",
    "        )\n",
    "\n",
    "        # Now find the Logout link within the dropdown\n",
    "        logout_link = WebDriverWait(logout_menu, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//a[contains(@href, \"logout\") and contains(@class, \"headerMenu\")]'))\n",
    "        )\n",
    "\n",
    "        # Scroll the logout link into view\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", logout_link)\n",
    "\n",
    "        # Click the logout link\n",
    "        logout_link.click()\n",
    "        print(\"Logout link clicked.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred during logout but do not worry!\")\n",
    "\n",
    "    # Close the browser after logging out\n",
    "    try:\n",
    "        driver.quit()\n",
    "        print(\"Logged out successfully!\")\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred while closing the browser.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e20d20c-f528-452d-bb89-c4e389df4f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4657aa7c-538b-46a7-b583-a784b2aeac8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "The above download process may take a while. Pay attention to the messages it generates. It might break in between due to factors like low internet speed or something. In that case, run the script again by changing the count variable value(according to the comment beside that variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31afc282-d7d5-432f-9569-4fd892588472",
   "metadata": {},
   "source": [
    "Lets process the downloaded data now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aafb761-1557-4c84-b9b7-894d1db9cdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to extract and make csv files:\n",
    "\n",
    "# Output file path for the text file\n",
    "output_file_path = DOWNLOAD_DIR +'/zipfiles.txt'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "all_files = os.listdir(DOWNLOAD_DIR)\n",
    "\n",
    "print(\"Total number of files:\",len(all_files))\n",
    "\n",
    "# Filter the list to only include zip files\n",
    "zip_files = [file for file in all_files if file.endswith('.zip')]\n",
    "\n",
    "print(\"Total number of zip_files:\",len(zip_files))\n",
    "\n",
    "# Print some information for debugging\n",
    "#print(\"Directory path:\", directory_path)\n",
    "#print(\"Zip files:\", zip_files)\n",
    "\n",
    "# Write the names of zip files to the text file\n",
    "with open(output_file_path, 'w') as file:\n",
    "    for zip_file in zip_files:\n",
    "        file.write(zip_file + '\\n')\n",
    "\n",
    "print(f\"File names written to {output_file_path}\")\n",
    "\n",
    "\n",
    "# Open the file in read mode\n",
    "with open(output_file_path, 'r') as file:\n",
    "    # Count the number of lines\n",
    "    line_count = sum(1 for line in file)\n",
    "\n",
    "# Print the result, it should match with the number of zip files.\n",
    "print(f'The number of lines/file names in the file is: {line_count}')\n",
    "\n",
    "#For debugging purposes:\n",
    "#for zip_file in zip_files:\n",
    "   #print(zip_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bb2c12-6105-480f-93d5-dfd11aa400ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to generate lightCurve.csv files for each zip file data\n",
    "\n",
    "# Specify the path to your input file\n",
    "input_file_path = DOWNLOAD_DIR + '/zipfiles.txt'\n",
    "\n",
    "\n",
    "i = 0\n",
    "# Open the file in read mode ('r')\n",
    "with open(input_file_path, 'r') as input_file:\n",
    "    # Read each line and use it as input for the code snippet\n",
    "    for line in input_file:\n",
    "        i = i+1\n",
    "        # Strip the newline character from the end of the line\n",
    "        line = line.strip()\n",
    "\n",
    "        #using the line as input\n",
    "        #if len(sys.argv) > 1:\n",
    "        #    zip_file_path = sys.argv[1]\n",
    "        #else:\n",
    "        zip_file_path = DOWNLOAD_DIR + '/'+line\n",
    "        print(zip_file_path)\n",
    "      \n",
    "       # ### Unzipping the CLASS L1 zip file and finding fits files within\n",
    "\n",
    "       \textract_to_path = DOWNLOAD_DIR +'/fits_files/'\n",
    "\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "             zip_ref.extractall(extract_to_path)\n",
    "\n",
    "        fits_files = []\n",
    "        # Recursive search for all files with a .fits extension\n",
    "        for root, dirs, files in os.walk(extract_to_path):\n",
    "            fits_files.extend(glob.glob(os.path.join(root, '*.fits')))\n",
    "\n",
    "\n",
    "        # ### Function to read fits file and retrieve the following\n",
    "        # 1. total counts, 2. Start time, and 3. End time\n",
    "\n",
    "\n",
    "        def read_FITS(fits_file_path):\n",
    "  \n",
    "            # Open the FITS file\n",
    "            with fits.open(fits_file_path) as hdul:\n",
    "            # Get the header from the primary HDU\n",
    "            \theader = hdul[1].header\n",
    "            \tdata = hdul[1].data['counts'][519:1187] #we are interested in this channel because we need 7-16 keV band data\n",
    "            \ttotal_counts = np.sum(data)\n",
    "        \n",
    "            # Check if the keyword is present in the header\n",
    "            if 'startime' in header:\n",
    "                start = header['startime']\n",
    "            else:\n",
    "                start = 'Not found'\n",
    "             \n",
    "            if 'endtime' in header:\n",
    "                end = header['endtime']\n",
    "            else:\n",
    "                end = 'Not found'\n",
    "            \n",
    "            return total_counts, start, end\n",
    "\n",
    "\n",
    "        # ### Function to estimate the mid time when start time and end time are given\n",
    "\n",
    "        def calculate_mid_time(start_time_str, end_time_str):\n",
    "    \n",
    "            if (start_time_str == 'Not found' or end_time_str == 'Not found'):\n",
    "                return 'Not found in FITS'\n",
    "            else:\n",
    "                # Parse the start and end time strings\n",
    "                start_time = datetime.strptime(start_time_str, \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "                end_time = datetime.strptime(end_time_str, \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "                \n",
    "                # Calculate the time difference between start and end times\n",
    "                time_difference = end_time - start_time\n",
    "                \n",
    "                # Calculate the mid time as half of the time difference added to the start time\n",
    "                mid_time = start_time + time_difference / 2\n",
    "                \n",
    "                return mid_time\n",
    "\n",
    "\n",
    "    # ### Generating CLASS light curve      \n",
    "        \n",
    "        Counts = []\n",
    "        time = []\n",
    "        \n",
    "        for f in fits_files:\n",
    "             c, s, e = read_FITS(f)\n",
    "             m = calculate_mid_time(s, e)\n",
    "            \n",
    "             Counts = np.append(Counts, c.astype('float'))\n",
    "             time = np.append(time, m.strftime('%Y-%m-%dT%H:%M:%S.%f'))\n",
    "            \n",
    "             light_curve = np.column_stack([time, Counts.astype('float')])\n",
    "             lc = pd.DataFrame(light_curve, columns=['time', 'total_counts'])\n",
    "             lc['time'] = pd.to_datetime(lc.time)\n",
    "             lc_sorted = lc.sort_values(by='time', ascending=True)\n",
    "             lc_sorted.to_csv(os.path.join(DOWNLOAD_DIR, 'LightCurve'+str(i)+'.csv'), index=False)\n",
    "\n",
    "            \n",
    "            \n",
    "     # ### Removing temporary files                \n",
    "                \n",
    "        if os.path.exists(extract_to_path):\n",
    "             try:\n",
    "                 shutil.rmtree(extract_to_path)  # Use this if the directory is empty\n",
    "             except OSError as e:\n",
    "                 pass\n",
    "        print('LightCurve'+str(i)+'.csv saved in current directory.')\n",
    "                        \n",
    "                        \n",
    "print(\"DONE!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc4668b-a557-4109-a70c-7e573ca1f2f1",
   "metadata": {},
   "source": [
    "Wait till Light Curve file is generated for each zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe02c32c-9e68-4a77-b63c-bb9d65200155",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to combine LightCurve csv files\n",
    "\n",
    "# Directory path where your CSV files are located\n",
    "#DOWNLOAD_DIR\n",
    "\n",
    "# Extract the month_year from the DOWNLOAD_DIR\n",
    "month_year = os.path.basename(os.path.dirname(DOWNLOAD_DIR))  \n",
    "\n",
    "\n",
    "files = os.path.join(DOWNLOAD_DIR,\"LightCurve*.csv\")\n",
    "files = glob.glob(files)\n",
    "\n",
    "df = pd.concat(map(pd.read_csv, files),ignore_index = True)\n",
    "print(df)\n",
    "\n",
    "# Write the resulting DataFrame to a CSV file named 'output.csv'\n",
    "# Construct the output file path\n",
    "output_file_path = os.path.join(os.path.dirname(DOWNLOAD_DIR), f'CombinedLightCurve{month_year}.csv')\n",
    "\n",
    "df.to_csv(output_file_path, index=False)\n",
    "print(f'Done!\\nCombinedLightCurve{month_year}.csv saved at {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c496a17-8ee6-4a89-82a6-f6d3e66b4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to sort the data in csv file\n",
    "\n",
    "# Directory path where your CSV files are located\n",
    "directory_path = os.path.dirname(DOWNLOAD_DIR) \n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "file_path = os.path.join(directory_path, f'CombinedLightCurve{month_year}.csv')  # Construct the file path dynamically\n",
    "df = pd.read_csv(file_path, header=None, names=['time', 'counts'])\n",
    "\n",
    "\n",
    "\n",
    "# Identify the first row\n",
    "first_row = df.iloc[0:1]\n",
    "\n",
    "\n",
    "# Convert 'time' to datetime format, specifying the format\n",
    "df['time'] = pd.to_datetime(df['time'], format='%Y-%m-%d %H:%M:%S.%f', errors='coerce')\n",
    "\n",
    "# Drop rows with NaT (Not a Time) values\n",
    "df = df.dropna(subset=['time'])\n",
    "# Sort the DataFrame by the 'time' column\n",
    "df_sorted = pd.concat([first_row, df.iloc[1:].sort_values(by='time')])\n",
    "\n",
    "\n",
    "# Save the sorted DataFrame back to the CSV file\n",
    "output_path = os.path.join(os.path.dirname(DOWNLOAD_DIR), f'CLASS_LC_{month_year}_sorted.csv')  # Construct the output file path dynamically\n",
    "df_sorted.to_csv(output_path, index=False, header=False)\n",
    "\n",
    "print(f'Data sorted and saved to {output_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357924dc-9b0c-424e-a950-5529cf30f8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b5bfaac-f0e1-4769-a3e8-7108f24781d4",
   "metadata": {},
   "source": [
    "### Code to plot CLASS data in 7-16keV range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d527fbd-aa7a-4b41-8a06-b8615a8028b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Construct the full file path\n",
    "file_path = os.path.join(os.path.dirname(DOWNLOAD_DIR), f'CLASS_LC_{month_year}_sorted.csv')\n",
    "\n",
    "# Read the data from the constructed file path into a DataFrame\n",
    "df2 = pd.read_csv(file_path)\n",
    "\n",
    "# Convert 'time' to datetime format\n",
    "df2['time'] = pd.to_datetime(df2['time'])\n",
    "\n",
    "# Create a single plot with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "\n",
    "# Plot the data\n",
    "ax1.plot(df2['time'], df2['total_counts'], marker='o', linestyle='dashdot', color='#0073bc', label='CLASS protons')\n",
    "ax1.set_xlabel('Time(UTC)')\n",
    "ax1.set_ylabel('Counts/8s in 7-16 keV', color='#0073bc')\n",
    "#ax1.legend(loc=\"upper right\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "# Create a twin Axes sharing the xaxis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Set the x-axis range (e.g., from '2023-01-13 00:00:00' to '2023-02-01 23:59:59')\n",
    "plt.xlim([pd.to_datetime(start), pd.to_datetime(end)])\n",
    "\n",
    "# Set ticks at each day\n",
    "ax1.xaxis.set_major_locator(DayLocator())\n",
    "ax1.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "#Uncomment for making fullmoon date ±3 days range\n",
    "# Mark the full moon on Aug 1 and the ±3 days range\n",
    "#full_moon_dates = pd.to_datetime(['2023-08-01'])\n",
    "#for date in full_moon_dates:\n",
    "#    plt.axvline(x=date, color='g', linestyle='--', label='Full Moon')\n",
    "#    plt.axvspan(date - pd.Timedelta(days=3), date + pd.Timedelta(days=3), color='g', alpha=0.2)\n",
    "\n",
    "#Uncomment for bluemoon\n",
    "# Mark the full moon on the date and the ±3 days range\n",
    "#full_moon_dates_bluemoon = pd.to_datetime(['2023-08-30'])\n",
    "#for date in full_moon_dates_bluemoon:\n",
    "#    plt.axvline(x=date, color='g', linestyle='--', label='Full Moon(BM)')\n",
    "#    plt.axvspan(date - pd.Timedelta(days=3), date + pd.Timedelta(days=3), color='g', alpha=0.2)\n",
    "\n",
    "\n",
    "\n",
    "# Rotate x-axis labels for both axes\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation='vertical')\n",
    "\n",
    "\n",
    "# Adjust layout to prevent clipping of labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Move legends to the right side top\n",
    "ax1.legend(loc=\"upper left\")\n",
    "ax2.legend(loc=\"upper right\")\n",
    "\n",
    "#Save the plot\n",
    "plt.savefig(os.path.join(os.path.dirname(DOWNLOAD_DIR),f'CLASS_LC_{month_year}.png'))\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Print confirmation of save\n",
    "print(f\"Plot saved as: {os.path.join(os.path.dirname(DOWNLOAD_DIR),f'CLASS_LC_{month_year}.png')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfbb99a-9709-404a-918d-6474e9ae85ea",
   "metadata": {},
   "source": [
    "Code Credits: [Vaishnav Sankar K](https://github.com/Vai838)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
